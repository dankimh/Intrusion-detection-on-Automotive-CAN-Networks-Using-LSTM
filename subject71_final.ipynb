{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp Arbitration_ID  DLC                     Data   Class  \\\n",
      "0        1.597708e+09            260    8  06 25 05 30 FF CF 71 55  Normal   \n",
      "1        1.597708e+09            329    8  4A C5 7E 8C 31 2D 01 10  Normal   \n",
      "2        1.597708e+09            38D    8  00 00 49 00 90 7F FE 01  Normal   \n",
      "3        1.597708e+09            420    8  50 1E 00 C8 FC 4F 6A 00  Normal   \n",
      "4        1.597708e+09            421    8  FE 07 00 FF E3 7F 00 52  Normal   \n",
      "...               ...            ...  ...                      ...     ...   \n",
      "1875126  1.599047e+09            153    8  20 A1 10 FF 00 FF 20 EF  Normal   \n",
      "1875127  1.599047e+09            220    8  10 24 7F 74 03 FF BF 71  Normal   \n",
      "1875128  1.599047e+09            329    8  D6 BF 7E 8C 32 2B 00 10  Normal   \n",
      "1875129  1.599047e+09            47F    8  04 E0 FF FF 00 7B 00 57  Normal   \n",
      "1875130  1.599047e+09            48A    8  00 00 07 41 03 02 60 88  Normal   \n",
      "\n",
      "                           abstime    monotime  aid_int  y  time_interval  \\\n",
      "0       2020-08-17 23:43:47.052591    0.000000      608  0            NaN   \n",
      "1       2020-08-17 23:43:47.053980    0.001389      809  0            NaN   \n",
      "2       2020-08-17 23:43:47.054670    0.002079      909  0            NaN   \n",
      "3       2020-08-17 23:43:47.054904    0.002313     1056  0            NaN   \n",
      "4       2020-08-17 23:43:47.055140    0.002549     1057  0            NaN   \n",
      "...                            ...         ...      ... ..            ...   \n",
      "1875126 2020-09-02 11:38:52.674568  337.389365      339  0       0.009985   \n",
      "1875127 2020-09-02 11:38:52.674812  337.389609      544  0       0.009994   \n",
      "1875128 2020-09-02 11:38:52.675044  337.389841      809  0       0.009623   \n",
      "1875129 2020-09-02 11:38:52.675285  337.390082     1151  0       0.020106   \n",
      "1875130 2020-09-02 11:38:52.676073  337.390870     1162  0       0.050029   \n",
      "\n",
      "        SubClass  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "...          ...  \n",
      "1875126   Normal  \n",
      "1875127   Normal  \n",
      "1875128   Normal  \n",
      "1875129   Normal  \n",
      "1875130   Normal  \n",
      "\n",
      "[1875131 rows x 11 columns]\n",
      "            Timestamp Arbitration_ID  DLC                     Data   Class  \\\n",
      "2410     1.597708e+09            340    8  00 00 00 24 76 01 45 30  Normal   \n",
      "2411     1.597708e+09            389    8  00 00 00 20 00 00 77 00  Normal   \n",
      "2412     1.597708e+09            47F    8  00 1E FF FA 00 78 00 76  Normal   \n",
      "2413     1.597708e+09            381    8  80 40 3C 00 00 20 0A 05  Normal   \n",
      "2414     1.597708e+09            130    8  CC 7F 14 80 00 00 0B C6  Normal   \n",
      "...               ...            ...  ...                      ...     ...   \n",
      "1875126  1.599047e+09            153    8  20 A1 10 FF 00 FF 20 EF  Normal   \n",
      "1875127  1.599047e+09            220    8  10 24 7F 74 03 FF BF 71  Normal   \n",
      "1875128  1.599047e+09            329    8  D6 BF 7E 8C 32 2B 00 10  Normal   \n",
      "1875129  1.599047e+09            47F    8  04 E0 FF FF 00 7B 00 57  Normal   \n",
      "1875130  1.599047e+09            48A    8  00 00 07 41 03 02 60 88  Normal   \n",
      "\n",
      "                           abstime    monotime  aid_int  y  time_interval  \\\n",
      "2410    2020-08-17 23:43:48.055986    1.003395      832  0       0.010204   \n",
      "2411    2020-08-17 23:43:48.056229    1.003638      905  0       0.019995   \n",
      "2412    2020-08-17 23:43:48.056473    1.003882     1151  0       0.019994   \n",
      "2413    2020-08-17 23:43:48.060255    1.007664      897  0       0.019995   \n",
      "2414    2020-08-17 23:43:48.060492    1.007901      304  0       0.010009   \n",
      "...                            ...         ...      ... ..            ...   \n",
      "1875126 2020-09-02 11:38:52.674568  337.389365      339  0       0.009985   \n",
      "1875127 2020-09-02 11:38:52.674812  337.389609      544  0       0.009994   \n",
      "1875128 2020-09-02 11:38:52.675044  337.389841      809  0       0.009623   \n",
      "1875129 2020-09-02 11:38:52.675285  337.390082     1151  0       0.020106   \n",
      "1875130 2020-09-02 11:38:52.676073  337.390870     1162  0       0.050029   \n",
      "\n",
      "        SubClass   entropy  \n",
      "2410         NaN  3.705266  \n",
      "2411         NaN  3.705266  \n",
      "2412         NaN  3.705266  \n",
      "2413         NaN  3.705266  \n",
      "2414         NaN  3.705266  \n",
      "...          ...       ...  \n",
      "1875126   Normal  3.704465  \n",
      "1875127   Normal  3.704465  \n",
      "1875128   Normal  3.704465  \n",
      "1875129   Normal  3.704465  \n",
      "1875130   Normal  3.705127  \n",
      "\n",
      "[1872558 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_dataset(path):\n",
    " df=pd.read_csv(path)\n",
    " \n",
    " assert df.isna().any().any()==False, 'There is at least one missing value.'\n",
    " assert df['Timestamp'].is_monotonic_increasing, 'Timestamp is not sorted.'\n",
    " \n",
    " df['abstime']=pd.to_datetime(df['Timestamp'], unit='s').round('us')\n",
    " df['monotime']=df['Timestamp']-df['Timestamp'].min()\n",
    " df['aid_int']=df['Arbitration_ID'].map(lambda x: int(x,16))\n",
    " df['y']=df['Class'].map({'Normal': 0, 'Attack': 1})\n",
    " \n",
    " df['time_interval']=df.groupby('Arbitration_ID')['Timestamp'].diff()\n",
    " \n",
    " return df\n",
    "dfx=[]\n",
    "for i in range(0,3):\n",
    "    df_stationary_path=\"./0_Preliminary/0_Training/Pre_train_D_{t}.csv\".format(t=i)\n",
    "    dfx.append(load_dataset(df_stationary_path))\n",
    "\n",
    "\n",
    "\n",
    "df_stationary=pd.concat([dfx[0],dfx[1],dfx[2]],ignore_index=True)\n",
    "\n",
    "print(df_stationary)\n",
    "\n",
    "def get_H(series_aid):\n",
    " count=series_aid.value_counts()\n",
    " p_i=count/series_aid.shape[0]\n",
    " return -(p_i*np.log(p_i)).sum()\n",
    "\n",
    "df_stationary['entropy']=df_stationary.rolling(window=2402,min_periods=2402,step=10)['aid_int'].apply(get_H)\n",
    "df_stationary['entropy']=df_stationary['entropy'].ffill()\n",
    "\n",
    "df_stationary_except_nan=df_stationary[(~df_stationary['time_interval'].isna())&(~df_stationary['entropy'].isna())]\n",
    "\n",
    "print(df_stationary_except_nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 00 00 24 76 01 45 30\n"
     ]
    }
   ],
   "source": [
    "print((df_stationary_except_nan['Data'].iloc[0]))\n",
    "datafield=[[int(i,16) for i in lst.split(' ')]+[-1]*(8-len(lst.split(' '))) for lst in df_stationary_except_nan['Data']]\n",
    "\n",
    "df_df=pd.DataFrame(datafield,columns=['datafield{i}'.format(i=z) for z in range(0,8)])\n",
    "#print(df_df)\n",
    "df_1=df_stationary_except_nan.reset_index()\n",
    "df_df=df_df.reset_index()\n",
    "df_final=pd.concat([df_1,df_df],axis=1)\n",
    "\n",
    "#df_final_y=df_final[df_final[\"y\"]==1]\n",
    "#df_final.drop(df_final[df_final[\"y\"]==1].index,axis=0,inplace=True)\n",
    "#print(df_final)\n",
    "\n",
    "features_stationary=df_final[['aid_int','time_interval','entropy','datafield0','datafield1','datafield2','datafield3','datafield4','datafield5','datafield6','datafield7']]\n",
    "labels_stationary=df_final['y']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#data_stationary_train, data_stationary_test, target_stationary_train, target_stationary_test=train_test_split(features_stationary, labels_stationary, test_size=0.10, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872558 1872558\n"
     ]
    }
   ],
   "source": [
    "print(len(features_stationary),len(labels_stationary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp Arbitration_ID  DLC                     Data   Class  \\\n",
      "2410     1.599047e+09            386    8  00 00 00 C0 00 40 00 80  Normal   \n",
      "2411     1.599047e+09            356    8  00 00 00 80 1A 00 00 00  Normal   \n",
      "2412     1.599047e+09            366    7     25 EC 0A 25 23 00 01  Normal   \n",
      "2413     1.599047e+09            367    8  00 00 00 00 00 00 C8 0A  Normal   \n",
      "2414     1.599047e+09            368    8  00 00 00 00 00 EC 0A 40  Normal   \n",
      "...               ...            ...  ...                      ...     ...   \n",
      "2000728  1.599048e+09            453    5           00 88 8D 00 E2  Normal   \n",
      "2000729  1.599048e+09            164    4              00 08 09 5E  Normal   \n",
      "2000730  1.599048e+09            394    8  00 C0 08 00 D8 53 96 FC  Normal   \n",
      "2000731  1.599048e+09            490    8  00 00 08 21 00 F0 3C 9E  Normal   \n",
      "2000732  1.599048e+09            387    8  C1 AA F8 50 00 B6 03 00  Normal   \n",
      "\n",
      "        SubClass                    abstime    monotime  aid_int  y  \\\n",
      "2410      Normal 2020-09-02 11:39:56.650515    1.003537      902  0   \n",
      "2411      Normal 2020-09-02 11:39:56.653112    1.006134      854  0   \n",
      "2412      Normal 2020-09-02 11:39:56.653326    1.006348      870  0   \n",
      "2413      Normal 2020-09-02 11:39:56.653570    1.006592      871  0   \n",
      "2414      Normal 2020-09-02 11:39:56.653816    1.006838      872  0   \n",
      "...          ...                        ...         ...      ... ..   \n",
      "2000728   Normal 2020-09-02 11:52:24.369165  748.722187     1107  0   \n",
      "2000729   Normal 2020-09-02 11:52:24.369333  748.722355      356  0   \n",
      "2000730   Normal 2020-09-02 11:52:24.369573  748.722595      916  0   \n",
      "2000731   Normal 2020-09-02 11:52:24.369812  748.722834     1168  0   \n",
      "2000732   Normal 2020-09-02 11:52:24.370049  748.723071      903  0   \n",
      "\n",
      "         time_interval   entropy  \n",
      "2410          0.020007  3.703945  \n",
      "2411          0.010089  3.703945  \n",
      "2412          0.010088  3.703945  \n",
      "2413          0.010085  3.703945  \n",
      "2414          0.010087  3.703945  \n",
      "...                ...       ...  \n",
      "2000728       0.019979  3.712839  \n",
      "2000729       0.009917  3.712839  \n",
      "2000730       0.019984  3.712451  \n",
      "2000731       0.050184  3.712451  \n",
      "2000732       0.019974  3.712451  \n",
      "\n",
      "[1998315 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "df_test=load_dataset(\"./0_Preliminary/1_Submission/Pre_submit_D.csv\")\n",
    "df_test['entropy']=df_test.rolling(window=2402,min_periods=2402,step=10)['aid_int'].apply(get_H)\n",
    "df_test['entropy']=df_test['entropy'].ffill()\n",
    "\n",
    "df_test_except_nan=df_test[(~df_test['time_interval'].isna())&(~df_test['entropy'].isna())]\n",
    "\n",
    "print(df_test_except_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafieldt=[[int(i,16) for i in lst.split(' ')]+[-1]*(8-len(lst.split(' '))) for lst in df_test_except_nan['Data']]\n",
    "\n",
    "df_dft=pd.DataFrame(datafieldt,columns=['datafield{i}'.format(i=z) for z in range(0,8)])\n",
    "#print(df_df)\n",
    "df_1t=df_test_except_nan.reset_index()\n",
    "df_dft=df_dft.reset_index()\n",
    "df_final_test=pd.concat([df_1t,df_dft],axis=1)\n",
    "\n",
    "#print(df_final)\n",
    "\n",
    "features_stationary_t=df_final_test[['aid_int','time_interval','entropy','datafield0','datafield1','datafield2','datafield3','datafield4','datafield5','datafield6','datafield7']]\n",
    "labels_stationary_t=df_final_test['y']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#data_stationary_train, data_stationary_test, target_stationary_train, target_stationary_test=train_test_split(features_stationary, labels_stationary, test_size=0.10, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 266438,  266442,  266445,  266449,  266451,  266454,  266457,  266460,\n",
      "        266462,  266464,\n",
      "       ...\n",
      "       1759248, 1759249, 1759253, 1759263, 1759265, 1759267, 1759271, 1759274,\n",
      "       1759276, 1759279],\n",
      "      dtype='int64', length=150485)\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         aid_int  time_interval   entropy  datafield0  datafield1  datafield2  \\\n",
      "0            832       0.010204  3.705266           0           0           0   \n",
      "1            905       0.019995  3.705266           0           0           0   \n",
      "2           1151       0.019994  3.705266           0          30         255   \n",
      "3            897       0.019995  3.705266         128          64          60   \n",
      "4            304       0.010009  3.705266         204         127          20   \n",
      "...          ...            ...       ...         ...         ...         ...   \n",
      "1872553      339       0.009985  3.704465          32         161          16   \n",
      "1872554      544       0.009994  3.704465          16          36         127   \n",
      "1872555      809       0.009623  3.704465         214         191         126   \n",
      "1872556     1151       0.020106  3.704465           4         224         255   \n",
      "1872557     1162       0.050029  3.705127           0           0           7   \n",
      "\n",
      "         datafield3  datafield4  datafield5  datafield6  datafield7  \n",
      "0                36         118           1          69          48  \n",
      "1                32           0           0         119           0  \n",
      "2               250           0         120           0         118  \n",
      "3                 0           0          32          10           5  \n",
      "4               128           0           0          11         198  \n",
      "...             ...         ...         ...         ...         ...  \n",
      "1872553         255           0         255          32         239  \n",
      "1872554         116           3         255         191         113  \n",
      "1872555         140          50          43           0          16  \n",
      "1872556         255           0         123           0          87  \n",
      "1872557          65           3           2          96         136  \n",
      "\n",
      "[1722073 rows x 11 columns] <class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print((features_stationary),type(labels_stationary),type(features_stationary_t),type(labels_stationary_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        aid_int  time_interval   entropy\n",
      "392607      356       0.009784  3.707086\n",
      "745156      608       0.009166  4.006286\n",
      "186096      320       0.010046  3.685664\n",
      "687930      854       0.010529  3.702993\n",
      "659323      809       0.010055  3.704665\n",
      "...         ...            ...       ...\n",
      "759363     1988       0.040123  4.005056\n",
      "535030      688       0.010243  3.716155\n",
      "573977      304       0.010024  3.663474\n",
      "189636     1173       0.100670  3.664708\n",
      "585903      897       0.019394  3.704550\n",
      "\n",
      "[798279 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fe_st=df_final[['aid_int','time_interval','entropy']]\n",
    "la_st=df_final['y']\n",
    "dstr,dste,tstr,tste=train_test_split(fe_st,la_st,test_size=0.10,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "def evaluation(model, data_test, target_test):\n",
    " prediction=model.predict(data_test)\n",
    " \n",
    " print(\"{}:\".format('Confusion matrix: \\n'),confusion_matrix(target_test,prediction))\n",
    " print(\"{}:\".format('Accuracy: \\n'),accuracy_score(target_test,prediction))\n",
    " print(\"{}:\".format('Precision: \\n'),precision_score(target_test,prediction))\n",
    " print(\"{}:\".format('Recall: \\n'),recall_score(target_test,prediction))\n",
    " print(\"{}:\".format('F1 score: \\n'),f1_score(target_test,prediction))\n",
    "\n",
    "data_stationary_train=np.array(data_stationary_train)\n",
    "data_stationary_test=np.array(data_stationary_test)\n",
    "target_stationary_train=np.array(target_stationary_train)\n",
    "target_stationary_test=np.array(target_stationary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Arbitration_ID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Data</th>\n",
       "      <th>Class</th>\n",
       "      <th>SubClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.599046e+09</td>\n",
       "      <td>164</td>\n",
       "      <td>4</td>\n",
       "      <td>00 08 12 5C</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.599046e+09</td>\n",
       "      <td>340</td>\n",
       "      <td>8</td>\n",
       "      <td>00 00 00 24 D6 01 B5 30</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.599046e+09</td>\n",
       "      <td>386</td>\n",
       "      <td>8</td>\n",
       "      <td>00 00 00 80 00 40 00 80</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.599046e+09</td>\n",
       "      <td>485</td>\n",
       "      <td>4</td>\n",
       "      <td>02 00 00 00</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.599046e+09</td>\n",
       "      <td>130</td>\n",
       "      <td>8</td>\n",
       "      <td>04 80 58 80 00 00 0E 56</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889390</th>\n",
       "      <td>1.599047e+09</td>\n",
       "      <td>153</td>\n",
       "      <td>8</td>\n",
       "      <td>20 A1 10 FF 00 FF 20 EF</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889391</th>\n",
       "      <td>1.599047e+09</td>\n",
       "      <td>220</td>\n",
       "      <td>8</td>\n",
       "      <td>10 24 7F 74 03 FF BF 71</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889392</th>\n",
       "      <td>1.599047e+09</td>\n",
       "      <td>329</td>\n",
       "      <td>8</td>\n",
       "      <td>D6 BF 7E 8C 32 2B 00 10</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889393</th>\n",
       "      <td>1.599047e+09</td>\n",
       "      <td>47F</td>\n",
       "      <td>8</td>\n",
       "      <td>04 E0 FF FF 00 7B 00 57</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889394</th>\n",
       "      <td>1.599047e+09</td>\n",
       "      <td>48A</td>\n",
       "      <td>8</td>\n",
       "      <td>00 00 07 41 03 02 60 88</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889395 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Timestamp Arbitration_ID  DLC                     Data   Class  \\\n",
       "0       1.599046e+09            164    4              00 08 12 5C  Normal   \n",
       "1       1.599046e+09            340    8  00 00 00 24 D6 01 B5 30  Normal   \n",
       "2       1.599046e+09            386    8  00 00 00 80 00 40 00 80  Normal   \n",
       "3       1.599046e+09            485    4              02 00 00 00  Normal   \n",
       "4       1.599046e+09            130    8  04 80 58 80 00 00 0E 56  Normal   \n",
       "...              ...            ...  ...                      ...     ...   \n",
       "889390  1.599047e+09            153    8  20 A1 10 FF 00 FF 20 EF  Normal   \n",
       "889391  1.599047e+09            220    8  10 24 7F 74 03 FF BF 71  Normal   \n",
       "889392  1.599047e+09            329    8  D6 BF 7E 8C 32 2B 00 10  Normal   \n",
       "889393  1.599047e+09            47F    8  04 E0 FF FF 00 7B 00 57  Normal   \n",
       "889394  1.599047e+09            48A    8  00 00 07 41 03 02 60 88  Normal   \n",
       "\n",
       "       SubClass  \n",
       "0        Normal  \n",
       "1        Normal  \n",
       "2        Normal  \n",
       "3        Normal  \n",
       "4        Normal  \n",
       "...         ...  \n",
       "889390   Normal  \n",
       "889391   Normal  \n",
       "889392   Normal  \n",
       "889393   Normal  \n",
       "889394   Normal  \n",
       "\n",
       "[889395 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./0_Preliminary/0_Training/Pre_train_D_2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_34 (LSTM)              (None, 11, 32)            4352      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 11, 32)            0         \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7777 (30.38 KB)\n",
      "Trainable params: 7777 (30.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "print(type(features_stationary.values))\n",
    "X=features_stationary.values\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(32, input_shape=(11, 1),return_sequences=True))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.LSTM(16))\n",
    "model.add(keras.layers.Dense(16))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=0.0001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data,target):\n",
    "    model.fit(data,target,epochs=5)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "58518/58518 [==============================] - 188s 3ms/step - loss: 0.0841 - accuracy: 0.9804\n",
      "Epoch 2/5\n",
      "58518/58518 [==============================] - 188s 3ms/step - loss: 0.0918 - accuracy: 0.9766\n",
      "Epoch 3/5\n",
      "58518/58518 [==============================] - 179s 3ms/step - loss: 0.0883 - accuracy: 0.9787\n",
      "Epoch 4/5\n",
      "58518/58518 [==============================] - 177s 3ms/step - loss: 0.0876 - accuracy: 0.9807\n",
      "Epoch 5/5\n",
      "58518/58518 [==============================] - 174s 3ms/step - loss: 0.0893 - accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "model=train(model,X,labels_stationary.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62448/62448 [==============================] - 65s 1ms/step\n",
      "DNN Confusion matrix: \n",
      ": [[1749163   47473]\n",
      " [  61815  139864]]\n",
      "DNN Accuracy: : 0.9453099236106419\n",
      "DNN Precision: : 0.7465903692276485\n",
      "DNN Recall: : 0.6934980835882765\n",
      "DNN F1 score: : 0.7190655397207313\n"
     ]
    }
   ],
   "source": [
    "#pred=model.predict()\n",
    "def evaluations(model, data_test, target_test):\n",
    " predictions=model.predict(data_test)\n",
    " preds_1d = predictions.flatten() # 차원 펴주기\n",
    " prediction = np.where(preds_1d > 0.5, 1 , 0)\n",
    " \n",
    " print(\"{}:\".format('DNN Confusion matrix: \\n'),confusion_matrix(target_test,prediction))\n",
    " print(\"{}:\".format('DNN Accuracy: '),accuracy_score(target_test,prediction))\n",
    " print(\"{}:\".format('DNN Precision: '),precision_score(target_test,prediction))\n",
    " print(\"{}:\".format('DNN Recall: '),recall_score(target_test,prediction))\n",
    " print(\"{}:\".format('DNN F1 score: '),f1_score(target_test,prediction))\n",
    "evaluations(model,features_stationary_t,labels_stationary_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=keras.Sequential()\n",
    "\n",
    "model_dnn.add(keras.layers.Dense(units=16,activation=\"relu\",input_shape=(11,)))\n",
    "model_dnn.add(keras.layers.Dense(units=16,activation=\"relu\"))\n",
    "model_dnn.add(keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 16)                192       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481 (1.88 KB)\n",
      "Trainable params: 481 (1.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dnn.summary()\n",
    "model_dnn.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "58518/58518 [==============================] - 25s 432us/step - loss: 0.0845 - accuracy: 0.9800\n",
      "Epoch 2/5\n",
      "58518/58518 [==============================] - 26s 441us/step - loss: 0.0782 - accuracy: 0.9823\n",
      "Epoch 3/5\n",
      "58518/58518 [==============================] - 25s 425us/step - loss: 0.0755 - accuracy: 0.9832\n",
      "Epoch 4/5\n",
      "58518/58518 [==============================] - 25s 426us/step - loss: 0.0740 - accuracy: 0.9837\n",
      "Epoch 5/5\n",
      "58518/58518 [==============================] - 25s 427us/step - loss: 0.0737 - accuracy: 0.9839\n"
     ]
    }
   ],
   "source": [
    "model_dnn=train(model_dnn,features_stationary,labels_stationary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62448/62448 [==============================] - 20s 317us/step\n",
      "DNN Confusion matrix: \n",
      ": [[1768394   28242]\n",
      " [  62284  139395]]\n",
      "DNN Accuracy: : 0.9546988337674491\n",
      "DNN Precision: : 0.831528839098767\n",
      "DNN Recall: : 0.6911726059728579\n",
      "DNN F1 score: : 0.7548819980721116\n"
     ]
    }
   ],
   "source": [
    "evaluations(model_s,features_stationary_t,labels_stationary_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
