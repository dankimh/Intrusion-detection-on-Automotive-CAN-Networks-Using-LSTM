{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_dataset(path):\n",
    "    df=pd.read_csv(path)\n",
    " \n",
    "    assert df.isna().any().any()==False, 'There is at least one missing value.'\n",
    "    assert df['Timestamp'].is_monotonic_increasing, 'Timestamp is not sorted.'\n",
    " \n",
    "    df['abstime']=pd.to_datetime(df['Timestamp'], unit='s').round('us')\n",
    "    df['monotime']=df['Timestamp']-df['Timestamp'].min()\n",
    "    df['aid_int']=df['Arbitration_ID'].map(lambda x: int(x,16))\n",
    "    df['y']=df['Class'].map({'Normal': 0, 'Attack': 1})\n",
    "\n",
    "    df['time_interval']=df.groupby('Arbitration_ID')['Timestamp'].diff()\n",
    "\n",
    "    return df\n",
    "dfx=[]\n",
    "for i in range(0,3):\n",
    "    df_stationary_path=\"./0_Preliminary/0_Training/Pre_train_D_{t}.csv\".format(t=i)\n",
    "    dfx.append(load_dataset(df_stationary_path))\n",
    "\n",
    "df_stationary=pd.concat([dfx[0],dfx[1],dfx[2]],ignore_index=True)\n",
    "\n",
    "def get_H(series_aid):\n",
    "    count=series_aid.value_counts()\n",
    "    p_i=count/series_aid.shape[0]\n",
    "    return -(p_i*np.log(p_i)).sum()\n",
    "\n",
    "df_stationary['entropy']=df_stationary.rolling(window=2402,min_periods=2402,step=10)['aid_int'].apply(get_H)\n",
    "df_stationary['entropy']=df_stationary['entropy'].ffill()\n",
    "\n",
    "df_stationary_except_nan=df_stationary[(~df_stationary['time_interval'].isna())&(~df_stationary['entropy'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 00 00 24 76 01 45 30\n"
     ]
    }
   ],
   "source": [
    "print((df_stationary_except_nan['Data'].iloc[0]))\n",
    "datafield=[[int(i,16) for i in lst.split(' ')]+[-1]*(8-len(lst.split(' '))) for lst in df_stationary_except_nan['Data']]\n",
    "\n",
    "df_df=pd.DataFrame(datafield,columns=['datafield{i}'.format(i=z) for z in range(0,8)])\n",
    "df_1=df_stationary_except_nan.reset_index()\n",
    "df_df=df_df.reset_index()\n",
    "df_final=pd.concat([df_1,df_df],axis=1)\n",
    "\n",
    "features_stationary=df_final[['aid_int','time_interval','entropy','datafield0','datafield1','datafield2','datafield3','datafield4','datafield5','datafield6','datafield7']]\n",
    "labels_stationary=df_final['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=load_dataset(\"./0_Preliminary/1_Submission/Pre_submit_D.csv\")\n",
    "df_test['entropy']=df_test.rolling(window=2402,min_periods=2402,step=10)['aid_int'].apply(get_H)\n",
    "df_test['entropy']=df_test['entropy'].ffill()\n",
    "\n",
    "df_test_except_nan=df_test[(~df_test['time_interval'].isna())&(~df_test['entropy'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafieldt=[[int(i,16) for i in lst.split(' ')]+[-1]*(8-len(lst.split(' '))) for lst in df_test_except_nan['Data']]\n",
    "\n",
    "df_dft=pd.DataFrame(datafieldt,columns=['datafield{i}'.format(i=z) for z in range(0,8)])\n",
    "df_1t=df_test_except_nan.reset_index()\n",
    "df_dft=df_dft.reset_index()\n",
    "df_final_test=pd.concat([df_1t,df_dft],axis=1)\n",
    "\n",
    "features_stationary_t=df_final_test[['aid_int','time_interval','entropy','datafield0','datafield1','datafield2','datafield3','datafield4','datafield5','datafield6','datafield7']]\n",
    "labels_stationary_t=df_final_test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 11, 32)            4352      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7777 (30.38 KB)\n",
      "Trainable params: 7777 (30.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X=features_stationary.values\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(32, input_shape=(11, 1),return_sequences=True))\n",
    "model.add(keras.layers.LSTM(16))\n",
    "model.add(keras.layers.Dense(16))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data,target):\n",
    "    model.fit(data,target,epochs=5,batch_size=16)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "117035/117035 [==============================] - 337s 3ms/step - loss: 0.0704 - accuracy: 0.9833\n",
      "Epoch 2/5\n",
      "117035/117035 [==============================] - 334s 3ms/step - loss: 0.0564 - accuracy: 0.9864\n",
      "Epoch 3/5\n",
      "117035/117035 [==============================] - 330s 3ms/step - loss: 0.0363 - accuracy: 0.9890\n",
      "Epoch 4/5\n",
      "117035/117035 [==============================] - 330s 3ms/step - loss: 0.0312 - accuracy: 0.9899\n",
      "Epoch 5/5\n",
      "117035/117035 [==============================] - 332s 3ms/step - loss: 0.0291 - accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "model=train(model,X,labels_stationary.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62448/62448 [==============================] - 68s 1ms/step\n",
      "Confusion matrix: \n",
      ": [[1790123    6513]\n",
      " [  36635  165044]]\n",
      "Accuracy: : 0.9784078085787276\n",
      "Precision: : 0.962035941407229\n",
      "Recall: : 0.8183499521516866\n",
      "F1 score: : 0.884394860088523\n"
     ]
    }
   ],
   "source": [
    "#pred=model.predict()\n",
    "def evaluations(model, data_test, target_test):\n",
    "    predictions=model.predict(data_test)\n",
    "    preds_1d = predictions.flatten()\n",
    "    prediction = np.where(preds_1d > 0.5, 1 , 0)\n",
    "\n",
    "    print(\"{}:\".format('Confusion matrix: \\n'),confusion_matrix(target_test,prediction))\n",
    "    print(\"{}:\".format('Accuracy: '),accuracy_score(target_test,prediction))\n",
    "    print(\"{}:\".format('Precision: '),precision_score(target_test,prediction))\n",
    "    print(\"{}:\".format('Recall: '),recall_score(target_test,prediction))\n",
    "    print(\"{}:\".format('F1 score: '),f1_score(target_test,prediction))\n",
    "evaluations(model,features_stationary_t,labels_stationary_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
